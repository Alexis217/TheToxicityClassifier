# 📝 Detector de Toxicidad con TensorFlow.js

**🔍 Analiza texto en busca de lenguaje tóxico usando IA directamente en el navegador.**

---

## 🚀 Características

- **🌐 100% Cliente-side**: No necesita servidor, todo se ejecuta en el navegador.
- **⚡ Modelo Pre-entrenado**: Utiliza el modelo de toxicidad de TensorFlow.js.
- **📊 Resultados Visuales**: Muestra porcentajes y barras de progreso para cada categoría.
- **🎯 7 Categorías de Análisis**:
  - 🤬 **Insultos**
  - 💢 **Odio**
  - 🚫 **Lenguaje explícito**
  - ⚠️ **Amenazas**
  - 👺 **Deshumanización**
  - 😤 **Lenguaje provocativo**
  - 🔞 **Contenido sexual explícito**

---

## 🛠️ Tecnologías

<p align="left">  
  <img src="https://img.shields.io/badge/TensorFlow.js-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="TensorFlow.js">  
  <img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black" alt="JavaScript">  
  <img src="https://img.shields.io/badge/HTML5-E34F26?style=for-the-badge&logo=html5&logoColor=white" alt="HTML5">  
  <img src="https://img.shields.io/badge/CSS3-1572B6?style=for-the-badge&logo=css3&logoColor=white" alt="CSS3">  
</p>

---

## 📦 Instalación

1. **Clona el repositorio** (o descarga el archivo HTML):

   ```bash
   git clone https://github.com/Alexis217/TheToxicityClassifier.git
   ```

2. **Abre el archivo `index.html`** en tu navegador:

   ```bash
   Con la extension live server:
   # abrelo en el navegador
   si no lo tienes instalado:
   # ve a las extensiones de visual studio code
   # busca live server
   # y haz click en la extension e instalala
   ```

3. **¡Listo!** El modelo se cargará automáticamente.

---

## 🖥️ Uso

1. **🤖 Espera a que se cargue el modelo.** esto puede tomar un momento.
2. **✍️ Escribe** un texto en el cuadro de entrada.
3. **🖱️ Haz clic** en _"Analizar Toxicidad"_.
4. **📈 Visualiza** los resultados por categoría.S

---

## 📌 Requisitos

- **Navegador moderno** (Chrome, Firefox, Edge, Safari)
- **Extensión live server** para visualizar el proyecto en el navegador
- **Conexión a Internet** (solo para la primera carga del modelo)

---

### 🌟 Créditos

- Basado en el artículo de [BekahHW](https://dev.to/bekahhw)
- Modelo de [TensorFlow.js Toxicity](https://github.com/tensorflow/tfjs-models/tree/master/toxicity)

---

<p align="center">  
  <a href="#-detector-de-toxicidad-con-tensorflowjs">⬆️ Volver al inicio</a>  
</p>

---

### 📋 Estructura del Proyecto

```
Toxicity_Classifier/
├── index.html          # Página principal
├── README.md           # Documento de este proyecto
```

---

✨ **¡Listo para detectar toxicidad en tiempo real!** ✨

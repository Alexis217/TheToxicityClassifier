# ğŸ“ Detector de Toxicidad con TensorFlow.js

**ğŸ” Analiza texto en busca de lenguaje tÃ³xico usando IA directamente en el navegador.**

---

## ğŸš€ CaracterÃ­sticas

- **ğŸŒ 100% Cliente-side**: No necesita servidor, todo se ejecuta en el navegador.
- **âš¡ Modelo Pre-entrenado**: Utiliza el modelo de toxicidad de TensorFlow.js.
- **ğŸ“Š Resultados Visuales**: Muestra porcentajes y barras de progreso para cada categorÃ­a.
- **ğŸ¯ 7 CategorÃ­as de AnÃ¡lisis**:
  - ğŸ¤¬ **Insultos**
  - ğŸ’¢ **Odio**
  - ğŸš« **Lenguaje explÃ­cito**
  - âš ï¸ **Amenazas**
  - ğŸ‘º **DeshumanizaciÃ³n**
  - ğŸ˜¤ **Lenguaje provocativo**
  - ğŸ” **Contenido sexual explÃ­cito**

---

## ğŸ› ï¸ TecnologÃ­as

<p align="left">  
  <img src="https://img.shields.io/badge/TensorFlow.js-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="TensorFlow.js">  
  <img src="https://img.shields.io/badge/JavaScript-F7DF1E?style=for-the-badge&logo=javascript&logoColor=black" alt="JavaScript">  
  <img src="https://img.shields.io/badge/HTML5-E34F26?style=for-the-badge&logo=html5&logoColor=white" alt="HTML5">  
  <img src="https://img.shields.io/badge/CSS3-1572B6?style=for-the-badge&logo=css3&logoColor=white" alt="CSS3">  
</p>

---

## ğŸ“¦ InstalaciÃ³n

1. **Clona el repositorio** (o descarga el archivo HTML):

   ```bash
   git clone https://github.com/Alexis217/TheToxicityClassifier.git
   ```

2. **Abre el archivo `index.html`** en tu navegador:

   ```bash
   Con la extension live server:
   # abrelo en el navegador
   si no lo tienes instalado:
   # ve a las extensiones de visual studio code
   # busca live server
   # y haz click en la extension e instalala
   ```

3. **Â¡Listo!** El modelo se cargarÃ¡ automÃ¡ticamente.

---

## ğŸ–¥ï¸ Uso

1. **ğŸ¤– Espera a que se cargue el modelo.** esto puede tomar un momento.
2. **âœï¸ Escribe** un texto en el cuadro de entrada.
3. **ğŸ–±ï¸ Haz clic** en _"Analizar Toxicidad"_.
4. **ğŸ“ˆ Visualiza** los resultados por categorÃ­a.S

---

## ğŸ“Œ Requisitos

- **Navegador moderno** (Chrome, Firefox, Edge, Safari)
- **ExtensiÃ³n live server** para visualizar el proyecto en el navegador
- **ConexiÃ³n a Internet** (solo para la primera carga del modelo)

---

### ğŸŒŸ CrÃ©ditos

- Basado en el artÃ­culo de [BekahHW](https://dev.to/bekahhw)
- Modelo de [TensorFlow.js Toxicity](https://github.com/tensorflow/tfjs-models/tree/master/toxicity)

---

<p align="center">  
  <a href="#-detector-de-toxicidad-con-tensorflowjs">â¬†ï¸ Volver al inicio</a>  
</p>

---

### ğŸ“‹ Estructura del Proyecto

```
Toxicity_Classifier/
â”œâ”€â”€ index.html          # PÃ¡gina principal
â”œâ”€â”€ README.md           # Documento de este proyecto
```

---

âœ¨ **Â¡Listo para detectar toxicidad en tiempo real!** âœ¨
